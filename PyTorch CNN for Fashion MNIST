{"cells":[{"cell_type":"code","source":"# 1. Import necessary libraries\nimport torch\nimport torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, etc.\nimport torch.optim as optim # For all optimization algorithms, SGD, Adam, etc.\nfrom torch.utils.data import DataLoader # Gives easier dataset management and creates mini-batches\nimport torchvision.datasets as datasets # Standard datasets\nimport torchvision.transforms as transforms # Transformations we can perform on our dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 2. Set device (use GPU if available, otherwise CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# 3. Define data transformations\n# We convert the image to a PyTorch Tensor and normalize its pixel values.\n# Normalization helps the model train more effectively.\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5,), (0.5,))] # Normalizes to range [-1, 1]\n)\n\n# 4. Load the Fashion MNIST dataset\n# Note: If you have the dataset from Kaggle, place the files in a 'data' folder\n# or change the root='./data' path to your directory.\n# download=True will download it if it's not found in the root directory.\ntrain_dataset = datasets.FashionMNIST(\n    root='./data', train=True, transform=transform, download=True\n)\ntest_dataset = datasets.FashionMNIST(\n    root='./data', train=False, transform=transform, download=True\n)\n\n# Create DataLoaders to feed data to the network in batches\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n\n# Define the human-readable class names\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n# 5. Define the CNN Model Architecture\n# This class defines the structure of our neural network.\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # First convolutional block: finds basic shapes (edges, curves)\n        # Input: 1 channel (grayscale), Output: 32 feature maps, Kernel: 3x3\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) # Summarizes features\n        \n        # Second convolutional block: combines basic shapes into more complex parts\n        # Input: 32 feature maps, Output: 64 feature maps, Kernel: 3x3\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)) # Summarizes again\n        \n        # Fully connected layers: The decision-maker\n        # The input size 64*7*7 is calculated from the output of the pooling layers.\n        # Initial image 28x28 -> pool1 -> 14x14 -> pool2 -> 7x7.\n        # We have 64 feature maps, so 64 * 7 * 7 = 3136.\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.dropout = nn.Dropout(0.5) # Regularization to prevent overfitting\n        self.fc2 = nn.Linear(128, 10) # Output layer with 10 classes\n\n    # Defines the forward pass: how data flows through the layers\n    def forward(self, x):\n        # Pass through first conv block\n        x = torch.relu(self.conv1(x))\n        x = self.pool1(x)\n        \n        # Pass through second conv block\n        x = torch.relu(self.conv2(x))\n        x = self.pool2(x)\n        \n        # Flatten the feature maps for the fully connected layers\n        x = x.reshape(x.shape[0], -1)\n        \n        # Pass through the classifier layers\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x) # Raw scores (logits) for each class\n        \n        return x\n\n# 6. Instantiate the model, define loss function and optimizer\nmodel = CNN().to(device)\ncriterion = nn.CrossEntropyLoss() # Measures the error/loss\noptimizer = optim.Adam(model.parameters(), lr=0.001) # Updates model weights to reduce loss\n\n# 7. Train the network\nnum_epochs = 15\nprint(\"Starting training...\")\n\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Move data and targets to the configured device\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # Forward pass: get predictions\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # Backward pass and optimization\n        optimizer.zero_grad() # Reset gradients to zero\n        loss.backward() # Calculate gradients\n        optimizer.step() # Update weights\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n\nprint(\"Training finished.\")\n\n# 8. Evaluate the model on the test set\ndef check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval() # Set model to evaluation mode\n\n    with torch.no_grad(): # No need to calculate gradients during evaluation\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n    accuracy = float(num_correct) / float(num_samples) * 100\n    print(f'Accuracy: {accuracy:.2f}%')\n    model.train() # Set model back to training mode\n    return accuracy\n\nprint(\"\\nChecking accuracy on test data...\")\ncheck_accuracy(test_loader, model)","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}