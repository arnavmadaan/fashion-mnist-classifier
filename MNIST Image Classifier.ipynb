{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMo7KvOR6HtTlD4OaNhUDWA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Image Classification Model on Fashion MNIST using Convolutional Neural Networks**"],"metadata":{"id":"jZyxmyrrarJE"}},{"cell_type":"markdown","source":["## Importing Libraries"],"metadata":{"id":"OuGjBvV289Ga"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn # All NN models\n","import torch.optim as optim # Loads all optimization models\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader # Gives easier dataset management\n","import torchvision.transforms as transforms # Transformations we can perform on our dataset"],"metadata":{"id":"a9-fkT_r9GAe","executionInfo":{"status":"ok","timestamp":1753007724242,"user_tz":-330,"elapsed":27,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Initial Setup\n","\n","Including check for GPU (Pytorch cuda). Defaults to CPU if not avaiable. (My system doens't have one hence using colab)\n"],"metadata":{"id":"NR5-y-SY9j6E"}},{"cell_type":"code","source":["# Set device (use GPU if available, otherwise CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Defining the data transformations (pre-processed operations applied to the image before it is fed to the network)\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))]\n",")\n","\n","# Load the Fashion MNIST dataset- This automatically loads the dataset from ./data directly using\n","# pytorch's torchvision library\n","\n","#Training Data\n","train_dataset = datasets.FashionMNIST(\n","    root='./data', train=True, transform=transform, download=True\n",")\n","\n","#testing data\n","test_dataset = datasets.FashionMNIST(\n","    root='./data', train=False, transform=transform, download=True\n",")\n","\n","# Create DataLoaders\n","# this will create batches to feed to the network (since it cannot process  60000 images at once)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n","\n","# Defining the class names\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8POJjRI59-AJ","executionInfo":{"status":"ok","timestamp":1753007737047,"user_tz":-330,"elapsed":6388,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}},"outputId":"2b4705df-89a1-4cfe-bfae-1aec0718a7f7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:01<00:00, 14.2MB/s]\n","100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n","100%|██████████| 4.42M/4.42M [00:01<00:00, 3.91MB/s]\n","100%|██████████| 5.15k/5.15k [00:00<00:00, 10.7MB/s]\n"]}]},{"cell_type":"markdown","source":["## **Defining the CNN model**\n","\n","### The working basics\n","\n","---\n","\n","\n","\n","1. ```__init__```sets up two convolution and pooling blocks (conv1/pool1 & conv2/pool2)\n","\n","2. The conv1 layer accepts a single channel image (grey scale). ```in_channels=1```\n","\n","3. The layer will look for 32 different basic patterns and\n","produce 32 different feature maps ```out_channels=32```\n","\n","4. pool1 will be the first pooling layer and will shrink the 32 feature maps from conv1 and shrink them\n","\n","5. conv2 will be the second convolution layer-\n","this will find more complex patterns using the simpler images in conv 1 (as explained in my notes)\n","\n","6. The conv and pool layers are feature extracters (2D)\n","but the calssification works in 1D, and this flattens the feature map to a single list of numbers (referred to notes)\n","\n","7. A dropout layer has been added to prevent the model from overfitting.\n","\n","\n","8. The forward method defines the flow of data through the network layers.\n","\n"],"metadata":{"id":"ON-awtqe_JxA"}},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # Convolutional Block 1\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\n","        # Convolutional Block 2\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\n","        # Classifier\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = self.pool1(x)\n","        x = torch.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        x = x.reshape(x.shape[0], -1)\n","        x = torch.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"gXORLR9eAD6L","executionInfo":{"status":"ok","timestamp":1753007749405,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Optimization\n","\n","CrossEntropyLoss and Adam optimizer are used to train the model."],"metadata":{"id":"rlLmbzWKJ-6d"}},{"cell_type":"code","source":["model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"XJKQijHsKM4A","executionInfo":{"status":"ok","timestamp":1753007753288,"user_tz":-330,"elapsed":263,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Training Loop\n","\n","One Epoch is one complete pass of the training data through the algorithm\n","\n","The data is moved to the GPU, and a forward pass is made to get the predictions. The loss is calculated.\n","\n","loss.backward() calculates the gradients.\n","\n","optimizer.step() updates the model's weights\n","\n","\n","After each epoch, the loss from the previous batch is printed.\n"],"metadata":{"id":"bovc-Jn1KPd8"}},{"cell_type":"code","source":["num_epochs = 15\n","print(\"Starting training...\")\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Move data to device\n","        data = data.to(device=device)\n","        targets = targets.to(device=device)\n","\n","        # Forward pass\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","print(\"Training finished.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIYBPor6Xgs3","executionInfo":{"status":"ok","timestamp":1753007968612,"user_tz":-330,"elapsed":211043,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}},"outputId":"f1c2ad79-cc77-4e1f-847c-1dd2bc014e04"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n","Epoch [1/15], Loss: 0.5718\n","Epoch [2/15], Loss: 0.6161\n","Epoch [3/15], Loss: 0.2944\n","Epoch [4/15], Loss: 0.0618\n","Epoch [5/15], Loss: 0.2491\n","Epoch [6/15], Loss: 0.1921\n","Epoch [7/15], Loss: 0.1410\n","Epoch [8/15], Loss: 0.1723\n","Epoch [9/15], Loss: 0.1864\n","Epoch [10/15], Loss: 0.1783\n","Epoch [11/15], Loss: 0.0659\n","Epoch [12/15], Loss: 0.1451\n","Epoch [13/15], Loss: 0.1600\n","Epoch [14/15], Loss: 0.1095\n","Epoch [15/15], Loss: 0.0683\n","Training finished.\n"]}]},{"cell_type":"markdown","source":["## Evaluating the model\n","\n","here the model is tested on unseen data."],"metadata":{"id":"U9HK_mc-Xjxj"}},{"cell_type":"code","source":["def check_accuracy(loader, model):\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval() # Set model to evaluation mode\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","    accuracy = float(num_correct) / float(num_samples) * 100\n","    print(f'Accuracy on the test set: {accuracy:.2f}%')\n","    model.train() # Set model back to training mode\n","    return accuracy\n","\n","check_accuracy(test_loader, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWruTKT5X6So","executionInfo":{"status":"ok","timestamp":1753007970818,"user_tz":-330,"elapsed":2164,"user":{"displayName":"Arnav Madaan","userId":"11803564757589805572"}},"outputId":"d32bbae1-8ce1-43a5-dc54-cd42937eafe6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test set: 92.03%\n"]},{"output_type":"execute_result","data":{"text/plain":["92.03"]},"metadata":{},"execution_count":11}]}]}